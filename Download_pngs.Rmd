```{r d-setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Download satellite images

The script downloads images from the CoastWatch ERDDAP server. These images will then be used in the other Rmd to make the gifs. In the Rmd file, `eval=FALSE` so that the files are not downloaded. You will need to change that or run chunks individually.

```{r d-packages}
require(png)
require(raster)
require(ggplot2)
require(grid)
```

### Step 1. Create folders

Specify the years you want to download.

```{r create_dir}
years <- 2015:2018
for(year in years){
fil_dir <- paste0("pngs/sst_", year)
if (!dir.exists(fil_dir)) dir.create(fil_dir)
}
```

### Step 2. Download pngs

We will download SST images from the Global SST & Sea Ice Analysis, L4 OSTIA, UK Met Office, Global, 0.05Â°, Daily, 
2013-present product.  [Here](https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.html) is the data access page for that dataset.

We will create a url for each day that we want to download.  The url will look like

```
https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.png?analysed_sst%5B(2014-12-31T12:00:00Z)%5D%5B(7.125):(15.125)%5D%5B(72.625):(78.375)%5D&.draw=surface&.vars=longitude%7Clatitude%7Canalysed_sst&.colorBar=%7C%7C%7C24%7C34%7C&.bgColor=0xffccccff&.trim=0&.size=300
```

We want to keep everything except the dates.  We will update the date for each image. To figure out the url, you can go to the page that will make a graph [Here](https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.graph), 
make your graph by futzing with the lat-lon and colorbar settings, then scroll to the bottom and copy the url. Here I have done that and then broken the url in to parts so I can remake with the new dates.

```{r spec_url_parts}
url1 <- "https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplUKMO_OSTIAv20.png?analysed_sst%5B("
url2 <- "T12:00:00Z)%5D%5B("
url3 <- "):("
url4 <- ")%5D%5B("
url5 <- "):("
mincol <- 7
maxcol <- 25
url6 <- paste0(
  ")%5D&.draw=surface&.vars=longitude%7Clatitude%7Canalysed_sst&.colorBar=%7C%7C%7C",
  mincol, "%7C", maxcol, "%7C&.bgColor=0xffccccff&.trim=0&.size="
)
size <- 300
```

Set up the lat-lon bounding box for the region you want to download.
```{r}
lon1 <- -128.975
lon2 <- -122.025
lat1 <- 40.025
lat2 <- 50.025
```

Now we go through each month in a year and download the pngs for that satellite image. Use `sep` to specify how many days apart to download. I use `sep=7` to get weekly images.

```{r download_pngs}
sep <- 7 # weekly
for(year in years){
for (mon in 1:12) {
  for (i in seq(1, 31, sep)) { # i is day
    # day needs to be like 01 instead of 1
    day <- formatC(i, width = 2, format = "d", flag = "0")
    month <- formatC(mon, width = 2, format = "d", flag = "0")
    # put the url together
    url <- paste0(
      url1, year, "-", month, "-", day, url2, lat1, url3, lat2, url4,
      lon1, url5, lon2, url6, size
    )
    # make the filename
    fil <- paste0(fil_dir, "/file-", year, "-", month, "-", day, ".png")
    # wrap in try() so doesn't crash if no file for that day
    try(download.file(url, destfile = fil, mode = "wb"))
  }
}
}
```

## Prepare the images

I am adding an annotation to the top with the year, month and day.  I could also create an image header and append that to the top.

### Step 1. Add header

```{r add_header}
for(year in years){
fil_dir <- paste0("pngs/sst_", year)
files <- list.files(path = fil_dir, pattern = "*.png", full.names = TRUE)
for (i in files) {
  yr <- stringr::str_split(i, "-")[[1]][2]
  mon <- month.abb[as.numeric(stringr::str_split(i, "-")[[1]][3])]
  day <- as.numeric(stringr::str_split(stringr::str_split(i, "-")[[1]][4], "[.]")[[1]][1])
  ann.text <- paste(yr, mon, day)
  img <- magick::image_read(i)
  img <- magick::image_annotate(img, ann.text, size = 20, color = "black", location = "+130+0")
  magick::image_write(img, i, "png")
}
}
```
  
### Step 2. Get rid of the footer

This code will crop the footer off the files. When we make a 4x4 gif we will need to have this removed.a

```{r}
# Here is how to make a cropped png
footersize <- 100 #will be different for different pngs
for(year in years){
fil_dir <- paste0("pngs/sst_", year)
files <- list.files(path = fil_dir, pattern = "*.png")
for (i in files) {
fil <- file.path(fil_dir, i)
img <- png::readPNG(fil)
dim_img <- dim(img)
img_height <- dim_img[1]-footersize
img_width <- dim_img[2]
png(file.path(fil_dir, paste0("crop-",i)), width=img_width, height=img_height)
grid::grid.raster(img[1:img_height,1:img_width,])
dev.off()
}
}
```

### Step 3. Make a legend

```{r}
img <- png::readPNG(fil) #read in last image
footersize <- 100 #will be different for different pngs
dim_img <- dim(img)
img_height <- dim_img[1]
img_width <- dim_img[2]
png("pngs/sst_legend.png",width=img_width, height=footersize)
grid::grid.raster(img[(img_height-footersize):img_height, 1:img_width, ])
dev.off()
```
